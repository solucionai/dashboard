# -*- coding: utf-8 -*-
"""estrutura.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U47R0K0SnSKWftzu6sydvopPfxN1pxlx

# Puxando os dados do Analytics
"""

# !pip install google-analytics-data
# !pip install dash dash-bootstrap-components plotly flask

from google.analytics.data_v1beta import BetaAnalyticsDataClient, RunReportRequest, DateRange, Dimension, Metric
import requests
from datetime import datetime, timedelta
from flask import Flask
import dash
from dash import dcc, html, Input, Output
import dash_bootstrap_components as dbc
import plotly.express as px

# Substitua pelo caminho para o seu arquivo de credenciais JSON
credentials_path = "gaAPI.json"

# Inicializar o cliente com credenciais
client = BetaAnalyticsDataClient.from_service_account_file(credentials_path)

# Defina seu ID da Propriedade do Google Analytics
property_id = "441600247"  # Substitua pelo seu property ID

# Função para buscar dados de Leads e Custo dos Leads
def fetch_lead_data(property_id, start_date, end_date):
    try:
        request = RunReportRequest(
            property=f"properties/{property_id}",
            dimensions=[Dimension(name="sessionCampaignName")],  # Campanhas associadas a leads
            metrics=[
                Metric(name="conversions"),  # Supondo que conversões estejam configuradas como geração de leads
                Metric(name="advertiserAdCost")  # Custo de anúncios que geraram leads
            ],
            date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
        )
        response = client.run_report(request)

        # Correção para extrair os valores das métricas corretamente
        data = [
            {
                "sessionCampaignName": row.dimension_values[0].value,  # Captura o valor da dimensão
                "conversions": row.metric_values[0].value,             # Captura o valor da primeira métrica
                "advertiserAdCost": row.metric_values[1].value         # Captura o valor da segunda métrica
            }
            for row in response.rows
        ]

        # Transformar em DataFrame
        df_analytics = pd.DataFrame(data)
        print("Dados do Google Analytics extraídos com sucesso.")
        return df_analytics
    except Exception as e:
        print(f"Erro ao extrair dados do Google Analytics: {e}")
        return pd.DataFrame()

# Extraindo dados para um período específico
df_analytics = fetch_lead_data(property_id, "2024-08-01", "2024-09-13")

df_analytics

"""# Puxando os dados da API do Pipedrive

"""

# Defina o seu API Token do Pipedrive
API_TOKEN = 'bbdd39fba4dab68ac0c03f4a629680f7429478ff'
BASE_URL = 'https://api.pipedrive.com/v1/'

# Função para extrair todos os dados de negócios utilizando paginação
def fetch_all_pipedrive_deals():
    all_deals = []
    start = 0
    limit = 100  # Número de registros por página

    while True:
        url = f'{BASE_URL}deals?start={start}&limit={limit}&api_token={API_TOKEN}'
        response = requests.get(url)

        if response.status_code == 200:
            deals = response.json().get('data', [])
            if not deals:
                break  # Encerra o loop se não houver mais dados

            all_deals.extend(deals)  # Adiciona os registros atuais à lista geral
            start += limit  # Atualiza o offset para a próxima página
        else:
            print(f"Erro ao extrair dados do Pipedrive: {response.status_code}")
            break

    # Converte todos os negócios extraídos em um DataFrame
    df_all_deals = pd.DataFrame(all_deals)
    print(f"Negócios do Pipedrive extraídos com sucesso. Total de registros: {len(df_all_deals)}")
    return df_all_deals

# Extraindo todos os dados de negócios
df_pipedrive = fetch_all_pipedrive_deals()

# # Verificar quantos números (ou ocorrências) existem em cada valor da coluna 'stage_id'
# stage_counts = df_final_limpo['Etapa_Final'].value_counts()

# # Exibir o resultado
# print(stage_counts)

df_pipedrive

# # Verificar quantos números (ou ocorrências) existem em cada valor da coluna 'stage_id'
# stage_counts = df_final_limpo['PROBLEMA'].value_counts()

# # Exibir o resultado
# print(stage_counts)

# # Selecionar uma linha aleatória
# random_row = df_etiquetas.sample(n=1)  # Seleciona uma linha aleatória

# # Exibir os valores da linha selecionada
# print("Exemplo de uma linha aleatória:")
# print(random_row)

# # Exibir um exemplo de cada coluna
# print("\nExemplo de cada coluna da linha aleatória:")
# for column in random_row.columns:
#     print(f"{column}: {random_row[column].values[0]}")

# # Calcular a porcentagem de cada valor na coluna 'owner_name'
# percentages = df_pipedrive['owner_name'].value_counts(normalize=True) * 100

# # Exibir as porcentagens
# print(percentages)

# import pandas as pd

# # Supondo que o seu DataFrame se chama df e possui a coluna 'lost_reason'
# # Exemplo: df = pd.read_csv('seu_arquivo.csv')

# # Contar a frequência de cada valor na coluna 'lost_reason'
# lost_reason_counts = df_final_limpo['lost_reason'].value_counts()

# # Calcular a porcentagem de cada valor
# lost_reason_percentages = lost_reason_counts / lost_reason_counts.sum() * 100

# # Exibir os resultados
# print(lost_reason_percentages)

"""# Puxando as etiquetas"""

# Carregar o arquivo etiquetas.xlsx
df_etiquetas = pd.read_excel('etiquetas.xlsx')

# Substituir valores nulos por 0
df_etiquetas = df_etiquetas.fillna(0)

# Salvar como CSV
df_etiquetas.to_csv('etiquetas.csv', index=False)
print("Arquivo etiquetas.xlsx convertido para etiquetas.csv com sucesso e valores nulos substituídos por 0.")

# Carregar o arquivo etiquetas.xlsx
df_etiquetas = pd.read_excel('etiquetas.xlsx')

# Substituir valores nulos e valores não numéricos por 0
df_etiquetas = df_etiquetas.apply(pd.to_numeric, errors='coerce').fillna(0)

# Converter colunas numéricas de float para int
df_etiquetas = df_etiquetas.astype(int)

# Renomear a coluna 'telefone' para 'numero_wpp'
df_etiquetas = df_etiquetas.rename(columns={'Telefone': 'numero_wpp'})

# Adicionar um '+' antes de todos os valores na coluna 'numero_wpp'
df_etiquetas['numero_wpp'] = df_etiquetas['numero_wpp'].apply(lambda x: f'+{x}')

# Salvar como CSV
df_etiquetas.to_csv('etiquetas.csv', index=False)
print("Arquivo etiquetas.xlsx convertido para etiquetas.csv com sucesso, valores nulos substituídos por 0, colunas numéricas convertidas para int, e coluna 'telefone' renomeada para 'numero_wpp'.")

df_etiquetas

# df_etiquetas.dtypes

"""# Puxando os dados do endpoint"""

# Função para buscar todos os dados do endpoint
def fetch_all_data(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            return pd.DataFrame(data)  # Converte os dados em um DataFrame
        else:
            print(f"Error: {response.status_code}, Detail: {response.json().get('detail', 'No detail provided')}")
    except requests.RequestException as e:
        print(f"Failed to make the request: {e}")
        return pd.DataFrame()

# URL do endpoint
url = "https://web-production-c353.up.railway.app/retrieve_all"

# Chamando a função e obtendo os dados
df_endpoint = fetch_all_data(url)

# Verificação básica dos dados
if df_endpoint.empty:
    print("Os dados não foram carregados corretamente. Verifique o endpoint ou o formato dos dados.")
    exit()

# Função para calcular o tempo em cada etapa com base nas colunas de timestamp
def calculate_stage_duration(row):
    created_at = pd.to_datetime(row['created_at'], errors='coerce')
    last_modified = pd.to_datetime(row['last_modified'], errors='coerce')
    if pd.isnull(created_at) or pd.isnull(last_modified):
        return 0  # Retorna 0 se houver erro de conversão
    duration = (last_modified - created_at).total_seconds() / 60  # Duração em minutos
    return duration

# Função para extrair a última etapa (flag) alcançada na jornada
def extract_final_stage(raw_data):
    try:
        flags = {
            'voo': int(raw_data.get('FLAG_VOO_JORNADA', 0)),
            'negativacao': int(raw_data.get('FLAG_NEGATIVACAO_JORNADA', 0)),
            'telefonia': int(raw_data.get('FLAG_SERV_TELEF_JORNADA', 0)),
            'bancario': int(raw_data.get('FLAG_SERV_BANCARIO_JORNADA', 0)),
            'compra_online': int(raw_data.get('FLAG_COMPRA_ONLINE_JORNADA', 0)),
            'outros': int(raw_data.get('FLAG_OUTROS_JORNADA', 0)),
            'hospedagem': int(raw_data.get('FLAG_HOSPEDAGEM_JORNADA', 0))
        }
        final_stage = max(flags.values())  # Encontra a maior flag para determinar a etapa final
        return final_stage
    except Exception as e:
        print(f"Erro ao extrair etapa final: {e}")
        return 0

# Aplicar as funções ao dataframe
df_endpoint['created_at'] = pd.to_datetime(df_endpoint['created_at'], errors='coerce')
df_endpoint['Tempo_na_Etapa'] = df_endpoint.apply(calculate_stage_duration, axis=1)
df_endpoint['Etapa_Final'] = df_endpoint['RAW_DATA'].apply(extract_final_stage)
# Substituir valores NaN por 0 em todas as colunas do df_endpoint
df_endpoint = df_endpoint.fillna(0)

# Lista de colunas de interesse
columns = [
    'FLAG_HOSPEDAGEM_JORNADA',
    'FLAG_OUTROS_JORNADA',
    'FLAG_VOO_JORNADA',
    'FLAG_COMPRA_ONLINE_JORNADA',
    'FLAG_SERV_BANCARIO_JORNADA',
    'FLAG_NEGATIVACAO_JORNADA',
    'FLAG_SERV_TELEF_JORNADA'
]

# Converter as colunas para numérico, ignorando erros e preenchendo com NaN para valores não convertíveis
for col in columns:
    df_endpoint[col] = pd.to_numeric(df_endpoint[col], errors='coerce')

# Calcular o valor máximo para cada coluna
max_values = {col: df_endpoint[col].max() for col in columns}

# Determinar o valor máximo global entre todas as flags
max_global = max(max_values.values())

print("Valores máximos de cada coluna:")
for col, max_val in max_values.items():
    print(f"{col}: {max_val}")

print(f"Valor máximo global: {max_global}")

# Criar a coluna FLAG_FINAL, onde 1 indica que a pessoa chegou ao fim e 0 indica que não
df_endpoint['FLAG_FINAL'] = df_endpoint[columns].max(axis=1).apply(lambda x: 1 if x == max_global else 0)

# Exibir as primeiras linhas para ver o resultado
print(df_endpoint[['FLAG_FINAL'] + columns].head())

# df_endpoint.head(30)

# # Contar o número total de registros
# total_registros = len(df_endpoint)

# # Contar o número de registros que chegaram ao final (FLAG_FINAL == 1)
# chegaram_ao_final = df_endpoint[df_endpoint['FLAG_FINAL'] == 1].shape[0]

# # Calcular a porcentagem
# percentual_chegaram_ao_final = (chegaram_ao_final / total_registros) * 100

# # Mostrar o resultado
# print(f"Porcentagem de pessoas que chegaram à etapa final: {percentual_chegaram_ao_final:.2f}%")

# # Selecionar uma linha aleatória
# random_row = df_endpoint.sample(n=1)  # Seleciona uma linha aleatória

# # Exibir os valores da linha selecionada
# print("Exemplo de uma linha aleatória:")
# print(random_row)

# # Exibir um exemplo de cada coluna
# print("\nExemplo de cada coluna da linha aleatória:")
# for column in random_row.columns:
#     print(f"{column}: {random_row[column].values[0]}")

df_pipedrive

# import pandas as pd

# def exibir_valores_unicos(df, df_name):
#     """
#     Exibe os valores únicos de cada coluna de um DataFrame, lidando com colunas de tipo dict.

#     Parâmetros:
#     - df: DataFrame do qual extrair os valores únicos.
#     - df_name: Nome do DataFrame para identificação nos outputs.
#     """
#     print(f"Valores únicos em cada coluna do DataFrame: {df_name}")
#     for column in df.columns:
#         try:
#             # Converter dicionários para strings para evitar erros de tipo
#             if df[column].apply(lambda x: isinstance(x, dict)).any():
#                 unique_values = df[column].apply(lambda x: str(x) if isinstance(x, dict) else x).unique()
#             else:
#                 unique_values = df[column].unique()

#             print(f"\nColuna: {column}")
#             print(f"Quantidade de valores únicos: {len(unique_values)}")
#             print(f"Valores únicos: {unique_values[:100]}")  # Exibe apenas os primeiros 10 valores para não sobrecarregar
#             print("-" * 50)
#         except Exception as e:
#             print(f"Erro ao processar a coluna: {column}, Erro: {e}")

# # Aplicando a função para cada DataFrame
# exibir_valores_unicos(df_pipedrive, "df_pipedrive")
# exibir_valores_unicos(df_endpoint, "df_endpoint")
# exibir_valores_unicos(df_analytics, "df_analytics")



"""# Unificação e tratamento de dados"""

# Duplicar os DataFrames
df_endpoint_dup = df_endpoint.copy()
df_pipedrive_dup = df_pipedrive.copy()
df_etiquetas_dup = df_etiquetas.copy()

# Quebrar a coluna 'title' no df_pipedrive_dup em três colunas
df_pipedrive_dup[['id2', 'Problema2', 'numero_wpp']] = df_pipedrive_dup['title'].str.extract(r'(\d+)\s*-\s*(.*?)\s*-\s*(\+\d+)')

# Remover a coluna original 'title' depois de extrair os valores
df_pipedrive_dup.drop('title', axis=1, inplace=True)

# Conferir se a operação foi realizada corretamente
print(df_pipedrive_dup.head())

# Supondo que você já tenha df_endpoint_dup e df_pipedrive_dup

# Passo 1: Remover duplicatas no numero_wpp para evitar dados inconsistentes
df_endpoint_dup_clean = df_endpoint_dup.drop_duplicates(subset='numero_wpp')
df_pipedrive_dup_clean = df_pipedrive_dup.drop_duplicates(subset='numero_wpp')

# Passo 2: Realizar o merge com base no numero_wpp (inner join para manter apenas os números em comum)
df_merged = pd.merge(df_pipedrive_dup_clean, df_endpoint_dup_clean, on='numero_wpp', how='inner', suffixes=('_pipedrive', '_endpoint'))

# Passo 3: Reorganizar as colunas para que 'numero_wpp' seja a primeira
cols = ['numero_wpp'] + [col for col in df_merged.columns if col != 'numero_wpp']
df_merged = df_merged[cols]

# Passo 4: Igualar os valores da coluna 'deal_id' aos valores da coluna 'pipedrive_deal_id'
df_merged['deal_id'] = df_merged['pipedrive_deal_id']

# Exibir o dataframe resultante para verificar a mudança
df_merged

# # Selecionar uma linha aleatória
# random_row = df_merged.sample(n=1)  # Seleciona uma linha aleatória

# # Exibir os valores da linha selecionada
# print("Exemplo de uma linha aleatória:")
# print(random_row)

# # Exibir um exemplo de cada coluna
# print("\nExemplo de cada coluna da linha aleatória:")
# for column in random_row.columns:
#     print(f"{column}: {random_row[column].values[0]}")

# # Checar as colunas das linhas específicas dos dataframes df_pipedrive e df_endpoint com base no numero_wpp fornecido

# numero_wpp_check = '+5521964324493'

# # Filtrando as linhas do df_pipedrive e df_endpoint onde numero_wpp é igual ao valor fornecido
# df_pipedrive_row = df_pipedrive_dup[df_pipedrive_dup['numero_wpp'] == numero_wpp_check]
# df_endpoint_row = df_endpoint_dup[df_endpoint_dup['numero_wpp'] == numero_wpp_check]

# # Exibindo as linhas filtradas com todos os valores
# print("Valores da linha do df_pipedrive:\n", df_pipedrive_row.to_string(index=False))
# print("Valores da linha do df_endpoint:\n", df_endpoint_row.to_string(index=False))

# df_etiquetas_dup

# Supondo que já temos o df_merged e o df_etiquetas_dup carregados

# 1. Certificar-se de que a coluna 'numero_wpp' está formatada corretamente em ambos os dataframes
df_merged['numero_wpp'] = df_merged['numero_wpp'].astype(str)
df_etiquetas_dup['numero_wpp'] = df_etiquetas_dup['numero_wpp'].astype(str)

# 2. Realizar o merge com base na coluna 'numero_wpp', mantendo apenas os números que já existem no df_merged
df_final = pd.merge(df_merged, df_etiquetas_dup, on='numero_wpp', how='left')

# 3. Exibir o resultado para verificar se a junção foi realizada corretamente
df_final

# Também podemos verificar a quantidade de linhas para garantir que o merge foi feito corretamente:
print(f"Quantidade de pessoas no df_final: {df_final['numero_wpp'].nunique()}")

# Remover todas as linhas onde o valor na coluna 'POSSÍVEL' seja NaN
df_final_limpo = df_final.dropna(subset=['POSSÍVEL'])

# Exibir as primeiras linhas do DataFrame resultante para verificação
df_final_limpo

# # Selecionar uma linha aleatória
# random_row = df_final_limpo.sample(n=1)  # Seleciona uma linha aleatória

# # Exibir os valores da linha selecionada
# print("Exemplo de uma linha aleatória:")
# print(random_row)

# # Exibir um exemplo de cada coluna
# print("\nExemplo de cada coluna da linha aleatória:")
# for column in random_row.columns:
#     print(f"{column}: {random_row[column].values[0]}")

def exibir_valores_unicos(df, df_name):
    """
    Exibe os valores únicos de cada coluna de um DataFrame, lidando com colunas de tipo dict.

    Parâmetros:
    - df: DataFrame do qual extrair os valores únicos.
    - df_name: Nome do DataFrame para identificação nos outputs.
    """
    print(f"Valores únicos em cada coluna do DataFrame: {df_name}")
    for column in df.columns:
        try:
            # Converter dicionários para strings para evitar erros de tipo
            if df[column].apply(lambda x: isinstance(x, dict)).any():
                unique_values = df[column].apply(lambda x: str(x) if isinstance(x, dict) else x).unique()
            else:
                unique_values = df[column].unique()

            print(f"\nColuna: {column}")
            print(f"Quantidade de valores únicos: {len(unique_values)}")
            print(f"Valores únicos: {unique_values[:100]}")  # Exibe apenas os primeiros 10 valores para não sobrecarregar
            print("-" * 50)
        except Exception as e:
            print(f"Erro ao processar a coluna: {column}, Erro: {e}")

# Aplicando a função para cada DataFrame
exibir_valores_unicos(df_final_limpo, "df_final_limpo")

# # Supondo que o DataFrame seja df_final_limpo

# # 1. Filtrar apenas os dados que não sejam da categoria 'Solucionaí'
# df_filtrado = df_final_limpo[df_final_limpo['owner_name'] != 'Solucionaí']

# # 2. Agrupar por 'owner_name' e contar quantos contratos foram assinados
# # Considerando que a coluna 'CONTRATO ASSINADO' contém 1 para assinado e 0 para não assinado
# contratos_assinados_por_atendente = df_filtrado.groupby('owner_name')['CONTRATO ASSINADO'].sum()

# # 3. Exibir o resultado
# print(contratos_assinados_por_atendente)

# import pandas as pd

# # Supondo que você já tenha um DataFrame chamado df com as colunas "CONTRATOS ASSINADOS" e "wpp_number"
# # Filtrando os números de WhatsApp que têm o valor 1 na coluna "CONTRATOS ASSINADOS"
# filtro_contratos_assinados = df_final_limpo[df_final_limpo['CONTRATO ASSINADO'] == 1]

# # Selecionando a coluna com os números de WhatsApp
# numeros_wpp = filtro_contratos_assinados['numero_wpp']

# # Exibindo os números de WhatsApp
# print(numeros_wpp)

# # Supondo que o DataFrame seja df_final_limpo

# # 1. Filtrar apenas os dados que não sejam da categoria 'Solucionaí'
# df_filtrado = df_final_limpo[df_final_limpo['owner_name'] != 'Solucionaí']

# # 2. Agrupar por 'owner_name' e contar quantos contratos foram assinados
# # Considerando que a coluna 'CONTRATO ASSINADO' contém 1 para assinado e 0 para não assinado
# contratos_assinados_por_atendente = df_filtrado.groupby('owner_name')['CONTRATO ASSINADO'].sum()

# # 3. Contar o total de contratos (considerando tanto assinados quanto não assinados)
# total_contratos_por_atendente = df_filtrado.groupby('owner_name')['CONTRATO ASSINADO'].count()

# # 4. Calcular a porcentagem de contratos assinados por atendente
# porcentagem_contratos_assinados = (contratos_assinados_por_atendente / total_contratos_por_atendente) * 100

# # 5. Exibir o resultado
# print(porcentagem_contratos_assinados)

# import pandas as pd

# # Função para consolidar duplicatas
# def consolidate_duplicates(df, subset_columns, aggregation_func='first'):
#     available_columns = [col for col in subset_columns if col in df.columns]

#     if not available_columns:
#         print(f"Nenhuma das colunas {subset_columns} está presente no DataFrame.")
#         return df

#     # Consolidar duplicatas com base nas colunas disponíveis
#     df_consolidated = df.groupby(available_columns).agg(aggregation_func).reset_index()
#     return df_consolidated

# # Resetar índices dos DataFrames para garantir índices únicos
# df_pipedrive = df_pipedrive.reset_index(drop=True)
# df_endpoint = df_endpoint.reset_index(drop=True)
# df_analytics = df_analytics.reset_index(drop=True)

# # Consolidar duplicatas corretamente
# df_pipedrive = consolidate_duplicates(df_pipedrive, subset_columns=['id'])  # Coluna 'id' usada como Lead ID
# df_endpoint = consolidate_duplicates(df_endpoint, subset_columns=['numero_wpp'])  # Coluna 'numero_wpp' usada como chave

# # Para df_analytics, certifique-se de que a coluna correta está sendo usada
# if 'campaign_name' in df_analytics.columns:
#     df_analytics = consolidate_duplicates(df_analytics, subset_columns=['campaign_name'])

# # Seleção e renomeação de colunas
# df_pipedrive = df_pipedrive[['id', 'status', 'value', 'won_time', 'lost_time', 'lost_reason']]
# df_pipedrive = df_pipedrive.rename(columns={
#     'id': 'Lead ID',
#     'status': 'Status',
#     'value': 'Valor do Negócio',
#     'won_time': 'Data Fechamento',
#     'lost_time': 'Data Fechamento',
#     'lost_reason': 'Motivo da Perda'
# })
# df_pipedrive['Fonte'] = 'Pipedrive'

# df_endpoint = df_endpoint[['numero_wpp', 'created_at', 'last_modified', 'Etapa_Final', 'Tempo_na_Etapa']]
# df_endpoint = df_endpoint.rename(columns={
#     'numero_wpp': 'Número WhatsApp',
#     'created_at': 'Data Captura',
#     'last_modified': 'Data Fechamento',
#     'Etapa_Final': 'Etapa Final',
#     'Tempo_na_Etapa': 'Tempo na Etapa (min)'
# })
# df_endpoint['Fonte'] = 'Bot'

# # Renomeando colunas do df_analytics
# if 'campaign_name' in df_analytics.columns:
#     df_analytics = df_analytics.rename(columns={
#         'campaign_name': 'Canal de Aquisição',
#         'advertiserAdCost': 'Custo do Lead'
#     })
#     df_analytics['Fonte'] = 'Analytics'

# # Resetar índices novamente para garantir unicidade
# df_pipedrive = df_pipedrive.reset_index(drop=True)
# df_endpoint = df_endpoint.reset_index(drop=True)
# df_analytics = df_analytics.reset_index(drop=True)

# # Verificar se há duplicatas nos índices novamente
# print("Verificando duplicatas nos índices...")
# print(f"Duplicatas em df_pipedrive: {df_pipedrive.index.duplicated().sum()}")
# print(f"Duplicatas em df_endpoint: {df_endpoint.index.duplicated().sum()}")
# print(f"Duplicatas em df_analytics: {df_analytics.index.duplicated().sum()}")

# # Garantir que não há duplicatas nos índices antes de concatenar
# df_pipedrive = df_pipedrive[~df_pipedrive.index.duplicated()]
# df_endpoint = df_endpoint[~df_endpoint.index.duplicated()]
# df_analytics = df_analytics[~df_analytics.index.duplicated()]

# # Forçar redefinição de índices e conversão de índices para garantir unicidade
# df_pipedrive.index = pd.RangeIndex(start=0, stop=len(df_pipedrive), step=1)
# df_endpoint.index = pd.RangeIndex(start=0, stop=len(df_endpoint), step=1)
# df_analytics.index = pd.RangeIndex(start=0, stop=len(df_analytics), step=1)

# # Concatenar DataFrames
# df_unificado = pd.concat([df_pipedrive, df_endpoint, df_analytics], ignore_index=True, sort=False)

# # Visualizar o DataFrame unificado
# print(df_unificado.head())

# Mapeamento de DDD para regiões
ddd_regioes = {
    'Centro-Oeste': [61, 62, 64, 65, 66, 67],
    'Nordeste': [82, 71, 73, 74, 75, 77, 85, 88, 98, 99, 83, 81, 87, 86, 89, 84, 79],
    'Norte': [68, 96, 92, 97, 91, 93, 94, 69, 95, 63],
    'Sudeste': [27, 28, 31, 32, 33, 34, 35, 37, 38, 21, 22, 24, 11, 12, 13, 14, 15, 16, 17, 18, 19],
    'Sul': [41, 42, 43, 44, 45, 46, 51, 53, 54, 55, 47, 48, 49]
}

# Função para mapear DDD para região
def map_ddd_to_regiao(ddd):
    for regiao, ddds in ddd_regioes.items():
        if int(ddd) in ddds:
            return regiao
    return 'Desconhecido'  # Caso o DDD não esteja mapeado

# Adiciona a coluna de Região ao DataFrame
df_final_limpo['Regiao'] = df_final_limpo['DDD'].apply(map_ddd_to_regiao)

# Dicionário para mapear os DDDs aos estados e regiões
# Dicionário para mapear os DDDs aos estados
ddd_mapping_estados = {
    61: 'Distrito Federal',
    62: 'Goiás', 64: 'Goiás',
    65: 'Mato Grosso', 66: 'Mato Grosso',
    67: 'Mato Grosso do Sul',
    82: 'Alagoas',
    71: 'Bahia', 73: 'Bahia', 74: 'Bahia', 75: 'Bahia', 77: 'Bahia',
    85: 'Ceará', 88: 'Ceará',
    98: 'Maranhão', 99: 'Maranhão',
    83: 'Paraíba',
    81: 'Pernambuco', 87: 'Pernambuco',
    86: 'Piauí', 89: 'Piauí',
    84: 'Rio Grande do Norte',
    79: 'Sergipe',
    68: 'Acre',
    96: 'Amapá',
    92: 'Amazonas', 97: 'Amazonas',
    91: 'Pará', 93: 'Pará', 94: 'Pará',
    69: 'Rondônia',
    95: 'Roraima',
    63: 'Tocantins',
    27: 'Espírito Santo', 28: 'Espírito Santo',
    31: 'Minas Gerais', 32: 'Minas Gerais', 33: 'Minas Gerais', 34: 'Minas Gerais',
    35: 'Minas Gerais', 37: 'Minas Gerais', 38: 'Minas Gerais',
    21: 'Rio de Janeiro', 22: 'Rio de Janeiro', 24: 'Rio de Janeiro',
    11: 'São Paulo', 12: 'São Paulo', 13: 'São Paulo', 14: 'São Paulo',
    15: 'São Paulo', 16: 'São Paulo', 17: 'São Paulo', 18: 'São Paulo', 19: 'São Paulo',
    41: 'Paraná', 42: 'Paraná', 43: 'Paraná', 44: 'Paraná', 45: 'Paraná', 46: 'Paraná',
    51: 'Rio Grande do Sul', 53: 'Rio Grande do Sul', 54: 'Rio Grande do Sul', 55: 'Rio Grande do Sul',
    47: 'Santa Catarina', 48: 'Santa Catarina', 49: 'Santa Catarina'
}

# Aplicando o mapeamento de DDDs para Estados
df_final_limpo['Estado'] = df_final_limpo['DDD'].map(ddd_mapping_estados)

# Calcular a porcentagem de cada valor único na coluna 'Regiao'
porcentagem_regiao = df_final_limpo['Regiao'].value_counts(normalize=True) * 100
print(porcentagem_regiao)

# Verifique se o df_final_limpo está carregado
if 'df_final_limpo' in locals():
    # Checando os valores únicos na coluna DDD
    valores_unicos_ddd = df_final_limpo['DDD'].unique()
    print("Valores únicos da coluna DDD:", valores_unicos_ddd)
else:
    print("O DataFrame df_final_limpo não está carregado.")

# Criando o mapeamento para renomear os valores de 'stage_id'
stage_mapping = {
    8: 'Em Análise',
    7: 'Recuperação',
    1: 'Captados'
}

# Aplicando o mapeamento com o uso de .loc para evitar o warning
df_final_limpo.loc[:, 'stage_id'] = df_final_limpo['stage_id'].map(stage_mapping)

# Exibindo os valores únicos para verificar se a mudança foi aplicada corretamente
print(df_final_limpo['stage_id'].unique())

# Filtrar os dados onde a coluna 'Regiao' tem o valor 'Norte'
norte_count = df_final_limpo[df_final_limpo['Regiao'] == 'Norte'].shape[0]

# Exibir a contagem
print(f"Quantidade de números na região Norte: {norte_count}")

# from flask import Flask
# import dash
# from dash import dcc, html, Input, Output
# import dash_bootstrap_components as dbc
# import plotly.express as px
# import pandas as pd
# from datetime import datetime, timedelta

# # Configuração do servidor Flask
# server = Flask(__name__)

# # Inicializar o app Dash com o servidor Flask, habilitando supressão de exceções de callback
# app = dash.Dash(__name__, server=server, external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)

# # Utilizando a base de dados df_final_limpo já carregada
# df = df_final_limpo

# # Aba de Leads
# def create_leads_tab():
#     return dbc.Col([
#         dcc.Tabs([
#             dcc.Tab(label='Resumo de Leads', children=[
#                 dbc.Row([
#                     # Exibir informações de leads captados no topo
#                     html.Div(id='leads-info-top', style={'textAlign': 'center', 'marginBottom': 20}),

#                     # Adicionando um filtro por tipo de problema
#                     dbc.Col([
#                         html.P("Selecione o tipo de problema:", className="lead"),
#                         dcc.Dropdown(
#                             id='problema-dropdown',
#                             options=[{'label': problema, 'value': problema} for problema in df['PROBLEMA'].unique()],
#                             value=df['PROBLEMA'].unique()[0] if not df.empty else None,  # Valor padrão
#                             clearable=False,
#                             style={'margin-bottom': '20px'}
#                         ),
#                         html.P("Selecione o intervalo de datas:", className="lead"),
#                         dcc.DatePickerRange(
#                             id='date-picker-range-leads',
#                             start_date=datetime.now() - timedelta(days=30),
#                             end_date=datetime.now(),
#                             display_format='DD/MM/YYYY',
#                             style={'margin-bottom': '20px'}
#                         )
#                     ], width=12)
#                 ]),

#                 # 1. Total de Leads por Período (colocado no topo)
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='total-leads-graph'), width=12),
#                 ]),

#                 # Outros gráficos
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='leads-problema-graph'), width=6),  # Gráfico de leads por problema
#                     dbc.Col(dcc.Graph(id='leads-ddd-graph'), width=6),  # Gráfico de leads por DDD
#                     dbc.Col(dcc.Graph(id='fluxo-completo-graph'), width=6),  # Leads que completaram o fluxo
#                     dbc.Col(dcc.Graph(id='contratos-tempo-graph'), width=6),  # Contratos fechados por tempo
#                 ]),

#                 # Exibir o gráfico "Tempo na Etapa por Lead (Filtrado)" no final
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='tempo-por-lead-wpp-graph'), width=12),  # Gráfico de tempo por lead por número de WhatsApp
#                 ]),

#                 # Exibir informações de leads captados também no rodapé
#                 dbc.Row([html.Div(id='leads-info', style={'textAlign': 'center', 'marginTop': 20})])
#             ]),

#             dcc.Tab(label='Análise Detalhada de Leads', children=[
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='tempo-etapa-graph'), width=6),  # Tempo médio por etapa
#                     dbc.Col(dcc.Graph(id='leads-nao-prosseguiram-graph'), width=6),  # Leads não prosseguiram
#                     dbc.Col(dcc.Graph(id='motivos-perda-leads-graph'), width=6),  # Motivos de perda
#                     dbc.Col(dcc.Graph(id='taxa-conversao-por-stage-graph'), width=12)  # Novo gráfico de taxa de conversão por stage_id
#                 ])
#             ])
#         ])
#     ])

# # Aba de Atendentes
# def create_atendentes_tab():
#     return dbc.Col([
#         dcc.Tabs([
#             dcc.Tab(label='Atendimentos por Atendente', children=[
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='atendimentos-por-dia-graph'), width=6),  # Quantidade de atendimentos por dia
#                     dbc.Col(dcc.Graph(id='tempo-por-lead-graph'), width=6),  # Tempo médio gasto por lead
#                     dbc.Col(dcc.Graph(id='interacoes-por-lead-graph'), width=6),  # Média de interações por lead
#                     dbc.Col(dcc.Graph(id='contratos-por-atendente-graph'), width=6),  # Contratos fechados por atendente
#                 ])
#             ])
#         ])
#     ])

# # Layout do Dashboard
# app.layout = dbc.Container([
#     dbc.Row([
#         dbc.Col([
#             html.H2("Dashboard de Dados Solucionaí", className="display-4"),
#             html.Hr(),
#             dcc.Tabs([
#                 dcc.Tab(label='Leads', children=[create_leads_tab()]),
#                 dcc.Tab(label='Atendentes', children=[create_atendentes_tab()])
#             ])
#         ], width=12),
#     ])
# ], fluid=True)

# # Callbacks para atualizar os gráficos dinamicamente
# @app.callback(
#     [Output('total-leads-graph', 'figure'),
#      Output('leads-problema-graph', 'figure'),
#      Output('leads-ddd-graph', 'figure'),
#      Output('fluxo-completo-graph', 'figure'),
#      Output('contratos-tempo-graph', 'figure'),
#      Output('tempo-etapa-graph', 'figure'),
#      Output('leads-nao-prosseguiram-graph', 'figure'),
#      Output('motivos-perda-leads-graph', 'figure'),
#      Output('atendimentos-por-dia-graph', 'figure'),
#      Output('tempo-por-lead-graph', 'figure'),
#      Output('interacoes-por-lead-graph', 'figure'),
#      Output('contratos-por-atendente-graph', 'figure'),
#      Output('taxa-conversao-por-stage-graph', 'figure'),
#      Output('leads-info', 'children'),
#      Output('leads-info-top', 'children')],  # Adicionar leads-info ao topo também
#     [Input('date-picker-range-leads', 'start_date'),
#      Input('date-picker-range-leads', 'end_date'),
#      Input('problema-dropdown', 'value')]
# )
# def update_graphs(start_date, end_date, selected_problema):
#     # Filtrar dados pela data
#     df_filtered = df[(df['created_at'] >= pd.to_datetime(start_date)) &
#                      (df['created_at'] <= pd.to_datetime(end_date))]

#     # Filtrar por problema, se um problema foi selecionado
#     if selected_problema:
#         df_filtered_by_problem = df_filtered[df_filtered['PROBLEMA'] == selected_problema]
#     else:
#         df_filtered_by_problem = df_filtered

#     # 1. Total de Leads Cadastrados na Base por Período de Tempo
#     leads_by_date = df_filtered.groupby(df_filtered['created_at'].dt.date).size()
#     fig_total_leads = px.line(x=leads_by_date.index, y=leads_by_date.values, title="Total de Leads por Período",
#                               labels={'x': 'Data', 'y': 'Número de Leads'})

#     # 2. Leads Cadastrados na Base por Tipo de Problema
#     leads_by_problem = df_filtered['PROBLEMA'].value_counts()
#     fig_leads_problema = px.bar(x=leads_by_problem.index, y=leads_by_problem.values, title="Leads por Tipo de Problema",
#                                 labels={'x': 'Tipo de Problema', 'y': 'Contagem de Leads'})

#     # 3. Leads Cadastrados por Região ou DDD
#     leads_by_ddd = df_filtered['Estado'].value_counts()

#     # Filtrar para exibir apenas os valores maiores que 1
#     leads_by_ddd = leads_by_ddd[leads_by_ddd > 1]

#     # Criar o gráfico apenas com os dados filtrados
#     fig_leads_ddd = px.bar(x=leads_by_ddd.index, y=leads_by_ddd.values, title="Leads por Região",
#                            labels={'x': 'Estado', 'y': 'Contagem de Leads'})

#     # 4. Leads que Responderam o Fluxo até o Final
#     completed_flow = df_filtered[df_filtered['COMPLETOU_O_FLUXO'] == 1].shape[0]
#     fig_fluxo_completo = px.pie(values=[completed_flow, df_filtered.shape[0] - completed_flow],
#                                 names=['Completaram', 'Não Completaram'],
#                                 title="Leads que Completaram o Fluxo até o Final")

#     # 5. Contratos Fechados por Tempo
#     contratos_by_date = df_filtered[df_filtered['CONTRATO ASSINADO'] == 1].groupby(df_filtered['created_at'].dt.date).size()
#     fig_contratos_tempo = px.line(x=contratos_by_date.index, y=contratos_by_date.values, title="Contratos Fechados por Período",
#                                   labels={'x': 'Data', 'y': 'Número de Contratos Fechados'})

#     # 6. Tempo Médio que o Lead Fica em Cada Etapa
#     avg_stage_time = df_filtered.groupby('Etapa_Final')['Tempo_na_Etapa'].mean()
#     fig_tempo_etapa = px.bar(x=avg_stage_time.index, y=avg_stage_time.values, title="Tempo Médio por Etapa",
#                              labels={'x': 'Etapa Final', 'y': 'Tempo Médio (minutos)'})

#     # 7. Leads que Não Prosseguiram
#     leads_nao_prosseguiram = df_filtered[(df['ClienteDesistiu'] == 1) | (df['SEM RESPOSTA'] == 1)].shape[0]
#     fig_leads_nao_prosseguiram = px.pie(values=[leads_nao_prosseguiram, df_filtered.shape[0] - leads_nao_prosseguiram],
#                                         names=['Não Prosseguiram', 'Prosseguiram'],
#                                         title="Leads que Não Prosseguiram após o Primeiro Contato")

#     # 8. Motivo de Perda dos Leads Não Elegíveis
#     motivo_perda = df_filtered[df_filtered['NÃO ELEGÍVEL'] == 1]['lost_reason'].value_counts()
#     fig_motivos_perda_leads = px.bar(x=motivo_perda.index, y=motivo_perda.values, title="Motivo de Perda dos Leads Não Elegíveis",
#                                      labels={'x': 'Motivo', 'y': 'Número de Leads Não Elegíveis'})

#     # Gráficos da aba Atendentes
#     atendimentos_por_dia = df_filtered.groupby([df_filtered['created_at'].dt.date, 'owner_name']).size().unstack().fillna(0)
#     fig_atendimentos_por_dia = px.line(atendimentos_por_dia, title="Atendimentos por Dia por Atendente",
#                                        labels={'x': 'Número de Atendimentos', 'y': 'Dia'})

#     tempo_por_lead = df_filtered.groupby('owner_name')['Tempo_na_Etapa'].mean()
#     fig_tempo_por_lead = px.bar(x=tempo_por_lead.index, y=tempo_por_lead.values, title="Tempo Médio por Lead por Atendente",
#                                 labels={'x': 'Atendente', 'y': 'Tempo Médio (minutos)'})

#     interacoes_por_lead = df_filtered.groupby('owner_name').size()
#     fig_interacoes_por_lead = px.bar(x=interacoes_por_lead.index, y=interacoes_por_lead.values, title="Interação de Atendentes com os Leads",
#                                      labels={'x': 'Atendente', 'y': 'Número de Leads'})

#     # 9. Contratos Fechados por Atendente
#     contratos_por_atendente = df_filtered[df_filtered['CONTRATO ASSINADO'] == 1].groupby('owner_name').size()
#     fig_contratos_por_atendente = px.bar(x=contratos_por_atendente.index, y=contratos_por_atendente.values, title="Contratos Fechados por Atendente",
#                                          labels={'x': 'Atendente', 'y': 'Número de Contratos Fechados'})

#     # 10. Taxa de conversão por stage_id
#     contratos_stage = df_filtered.groupby('stage_id')['CONTRATO ASSINADO'].sum()
#     leads_stage = df_filtered.groupby('stage_id').size()
#     conversao_stage = (contratos_stage / leads_stage * 100).fillna(0)

#     fig_conversao_stage = px.bar(x=conversao_stage.index, y=conversao_stage.values, title="Taxa de Conversão por Stage",
#                                  labels={'x': 'Stage', 'y': 'Taxa de Conversão (%)'})

#     # Calcular métricas de leads
#     leads_captados_total = len(df_filtered)
#     leads_captados = len(df_filtered_by_problem)
#     proporcao_responderam = (leads_captados / leads_captados_total) * 100 if leads_captados_total > 0 else 0

#     leads_info = [
#         html.H4(f"Leads Captados no Problema Selecionado: {leads_captados}"),
#         html.H4(f"Total de Leads Captados: {leads_captados_total}"),
#         html.H4(f"Proporção de Leads no Problema Selecionado: {proporcao_responderam:.2f}%"),
#     ]

#     return (fig_total_leads, fig_leads_problema, fig_leads_ddd, fig_fluxo_completo, fig_contratos_tempo,
#             fig_tempo_etapa, fig_leads_nao_prosseguiram, fig_motivos_perda_leads,
#             fig_atendimentos_por_dia, fig_tempo_por_lead, fig_interacoes_por_lead,
#             fig_contratos_por_atendente, fig_conversao_stage, leads_info, leads_info)

# # Callback para o gráfico de tempo na etapa por número de WhatsApp com filtro por problema
# @app.callback(
#     Output('tempo-por-lead-wpp-graph', 'figure'),
#     [Input('problema-dropdown', 'value'),
#      Input('date-picker-range-leads', 'start_date'),
#      Input('date-picker-range-leads', 'end_date')]
# )
# def update_tempo_por_lead_graph(selected_problema, start_date, end_date):
#     # Filtrar dados pela data e pelo problema selecionado
#     df_filtered = df[(df['created_at'] >= pd.to_datetime(start_date)) &
#                      (df['created_at'] <= pd.to_datetime(end_date))]

#     # Filtrar por problema, se um problema foi selecionado
#     if selected_problema:
#         df_filtered = df_filtered[df_filtered['PROBLEMA'] == selected_problema]

#     # Remover valores de tempo na etapa acima de 40 minutos e valores 0
#     df_filtered = df_filtered[(df_filtered['Tempo_na_Etapa'] <= 40) & (df_filtered['Tempo_na_Etapa'] > 0)]

#     # Gráfico de barras para tempo por lead (número de WhatsApp)
#     fig_tempo_por_lead_wpp = px.bar(
#         df_filtered,
#         x='numero_wpp',
#         y='Tempo_na_Etapa',
#         title='Tempo na Etapa por Lead (Filtrado)',
#         labels={'Tempo_na_Etapa': 'Tempo na Etapa (minutos)', 'numero_wpp': 'Número WhatsApp'},
#         hover_data={'Etapa_Final': True}  # Adiciona a etapa final ao hover
#     )

#     return fig_tempo_por_lead_wpp

# if __name__ == '__main__':
#     app.run_server(debug=True)

# from flask import Flask
# import dash
# from dash import dcc, html, Input, Output
# import dash_bootstrap_components as dbc
# import plotly.express as px
# import pandas as pd
# from datetime import datetime, timedelta

# # Configuração do servidor Flask
# server = Flask(__name__)

# # Inicializar o app Dash com o servidor Flask, habilitando supressão de exceções de callback
# app = dash.Dash(__name__, server=server, external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)

# # Utilizando a base de dados df_final_limpo já carregada
# df = df_final_limpo

# # Aba de Leads
# def create_leads_tab():
#     return dbc.Col([
#         dcc.Tabs([
#             dcc.Tab(label='Resumo de Leads', children=[
#                 dbc.Row([
#                     # Adicionando um filtro por tipo de problema
#                     dbc.Col([
#                         html.P("Selecione o tipo de problema:", className="lead"),
#                         dcc.Dropdown(
#                             id='problema-dropdown',
#                             options=[{'label': problema, 'value': problema} for problema in df['PROBLEMA'].unique()],
#                             value=df['PROBLEMA'].unique()[0] if not df.empty else None,  # Valor padrão
#                             clearable=False,
#                             style={'margin-bottom': '20px'}
#                         ),
#                         html.P("Selecione o intervalo de datas:", className="lead"),
#                         dcc.DatePickerRange(
#                             id='date-picker-range-leads',
#                             start_date=datetime.now() - timedelta(days=30),
#                             end_date=datetime.now(),
#                             display_format='DD/MM/YYYY',
#                             style={'margin-bottom': '20px'}
#                         )
#                     ], width=12)
#                 ]),

#                 # 1. Total de Leads por Período (primeiro gráfico)
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='total-leads-graph'), width=12),
#                 ]),

#                 # Informações de leads captados (movidas para abaixo do gráfico)
#                 dbc.Row([
#                     html.Div(id='leads-info', style={'textAlign': 'center', 'marginTop': 20, 'marginBottom': 20}),
#                 ]),

#                 # Outros gráficos
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='leads-problema-graph'), width=6),  # Gráfico de leads por problema
#                     dbc.Col(dcc.Graph(id='leads-ddd-graph'), width=6),  # Gráfico de leads por DDD
#                     dbc.Col(dcc.Graph(id='fluxo-completo-graph'), width=6),  # Leads que completaram o fluxo
#                     dbc.Col(dcc.Graph(id='contratos-tempo-graph'), width=6),  # Contratos fechados por tempo
#                 ]),

#                 # Exibir o gráfico "Tempo na Etapa por Lead (Filtrado)" no final
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='tempo-por-lead-wpp-graph'), width=12),  # Gráfico de tempo por lead por número de WhatsApp
#                 ]),
#             ]),

#             dcc.Tab(label='Análise Detalhada de Leads', children=[
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='tempo-etapa-graph'), width=6),  # Tempo médio por etapa
#                     dbc.Col(dcc.Graph(id='leads-nao-prosseguiram-graph'), width=6),  # Leads não prosseguiram
#                     dbc.Col(dcc.Graph(id='motivos-perda-leads-graph'), width=6),  # Motivos de perda
#                     dbc.Col(dcc.Graph(id='taxa-conversao-por-stage-graph'), width=12)  # Novo gráfico de taxa de conversão por stage_id
#                 ])
#             ])
#         ])
#     ])

# # Aba de Atendentes
# def create_atendentes_tab():
#     return dbc.Col([
#         dcc.Tabs([
#             dcc.Tab(label='Atendimentos por Atendente', children=[
#                 dbc.Row([
#                     dbc.Col(dcc.Graph(id='atendimentos-por-dia-graph'), width=6),  # Quantidade de atendimentos por dia
#                     dbc.Col(dcc.Graph(id='tempo-por-lead-graph'), width=6),  # Tempo médio gasto por lead
#                     dbc.Col(dcc.Graph(id='interacoes-por-lead-graph'), width=6),  # Média de interações por lead
#                     dbc.Col(dcc.Graph(id='contratos-por-atendente-graph'), width=6),  # Contratos fechados por atendente
#                 ])
#             ])
#         ])
#     ])

# # Layout do Dashboard
# app.layout = dbc.Container([
#     dbc.Row([
#         dbc.Col([
#             html.H2("Dashboard de Dados Solucionaí", className="display-4"),
#             html.Hr(),
#             dcc.Tabs([
#                 dcc.Tab(label='Leads', children=[create_leads_tab()]),
#                 dcc.Tab(label='Atendentes', children=[create_atendentes_tab()])
#             ])
#         ], width=12),
#     ])
# ], fluid=True)

# # Callbacks para atualizar os gráficos dinamicamente
# @app.callback(
#     [Output('total-leads-graph', 'figure'),
#      Output('leads-problema-graph', 'figure'),
#      Output('leads-ddd-graph', 'figure'),
#      Output('fluxo-completo-graph', 'figure'),
#      Output('contratos-tempo-graph', 'figure'),
#      Output('tempo-etapa-graph', 'figure'),
#      Output('leads-nao-prosseguiram-graph', 'figure'),
#      Output('motivos-perda-leads-graph', 'figure'),
#      Output('atendimentos-por-dia-graph', 'figure'),
#      Output('tempo-por-lead-graph', 'figure'),
#      Output('interacoes-por-lead-graph', 'figure'),
#      Output('contratos-por-atendente-graph', 'figure'),
#      Output('taxa-conversao-por-stage-graph', 'figure'),
#      Output('leads-info', 'children')],  # Informações de leads apenas abaixo do primeiro gráfico
#     [Input('date-picker-range-leads', 'start_date'),
#      Input('date-picker-range-leads', 'end_date'),
#      Input('problema-dropdown', 'value')]
# )
# def update_graphs(start_date, end_date, selected_problema):
#     # Filtrar dados pela data
#     df_filtered = df[(df['created_at'] >= pd.to_datetime(start_date)) &
#                      (df['created_at'] <= pd.to_datetime(end_date))]

#     # Filtrar por problema, se um problema foi selecionado
#     if selected_problema:
#         df_filtered_by_problem = df_filtered[df_filtered['PROBLEMA'] == selected_problema]
#     else:
#         df_filtered_by_problem = df_filtered

#     # 1. Total de Leads Cadastrados na Base por Período de Tempo
#     leads_by_date = df_filtered.groupby(df_filtered['created_at'].dt.date).size()
#     fig_total_leads = px.line(x=leads_by_date.index, y=leads_by_date.values, title="Total de Leads por Período",
#                               labels={'x': 'Data', 'y': 'Número de Leads'})

#     # 2. Leads Cadastrados na Base por Tipo de Problema
#     leads_by_problem = df_filtered['PROBLEMA'].value_counts()
#     fig_leads_problema = px.bar(x=leads_by_problem.index, y=leads_by_problem.values, title="Leads por Tipo de Problema",
#                                 labels={'x': 'Tipo de Problema', 'y': 'Contagem de Leads'})

#     # 3. Leads Cadastrados por Região ou DDD
#     leads_by_ddd = df_filtered['Estado'].value_counts()

#     # Filtrar para exibir apenas os valores maiores que 1
#     leads_by_ddd = leads_by_ddd[leads_by_ddd > 1]

#     # Criar o gráfico apenas com os dados filtrados
#     fig_leads_ddd = px.bar(x=leads_by_ddd.index, y=leads_by_ddd.values, title="Leads por Região",
#                            labels={'x': 'Estado', 'y': 'Contagem de Leads'})

#     # 4. Leads que Responderam o Fluxo até o Final
#     completed_flow = df_filtered[df_filtered['COMPLETOU_O_FLUXO'] == 1].shape[0]
#     fig_fluxo_completo = px.pie(values=[completed_flow, df_filtered.shape[0] - completed_flow],
#                                 names=['Completaram', 'Não Completaram'],
#                                 title="Leads que Completaram o Fluxo até o Final")

#     # 5. Contratos Fechados por Tempo
#     contratos_by_date = df_filtered[df_filtered['CONTRATO ASSINADO'] == 1].groupby(df_filtered['created_at'].dt.date).size()
#     fig_contratos_tempo = px.line(x=contratos_by_date.index, y=contratos_by_date.values, title="Contratos Fechados por Período",
#                                   labels={'x': 'Data', 'y': 'Número de Contratos Fechados'})

#     # 6. Tempo Médio que o Lead Fica em Cada Etapa
#     avg_stage_time = df_filtered.groupby('Etapa_Final')['Tempo_na_Etapa'].mean()
#     fig_tempo_etapa = px.bar(x=avg_stage_time.index, y=avg_stage_time.values, title="Tempo Médio por Etapa",
#                              labels={'x': 'Etapa Final', 'y': 'Tempo Médio (minutos)'})

#     # 7. Leads que Não Prosseguiram
#     leads_nao_prosseguiram = df_filtered[(df['ClienteDesistiu'] == 1) | (df['SEM RESPOSTA'] == 1)].shape[0]
#     fig_leads_nao_prosseguiram = px.pie(values=[leads_nao_prosseguiram, df_filtered.shape[0] - leads_nao_prosseguiram],
#                                         names=['Não Prosseguiram', 'Prosseguiram'],
#                                         title="Leads que Não Prosseguiram após o Primeiro Contato")

#     # 8. Motivo de Perda dos Leads Não Elegíveis
#     motivo_perda = df_filtered[df_filtered['NÃO ELEGÍVEL'] == 1]['lost_reason'].value_counts()
#     fig_motivos_perda_leads = px.bar(x=motivo_perda.index, y=motivo_perda.values, title="Motivo de Perda dos Leads Não Elegíveis",
#                                      labels={'x': 'Motivo', 'y': 'Número de Leads Não Elegíveis'})

#     #
#     # Gráficos da aba Atendentes
#     atendimentos_por_dia = df_filtered.groupby([df_filtered['created_at'].dt.date, 'owner_name']).size().unstack().fillna(0)
#     fig_atendimentos_por_dia = px.line(atendimentos_por_dia, title="Atendimentos por Dia por Atendente",
#                                        labels={'x': 'Número de Atendimentos', 'y': 'Dia'})

#     tempo_por_lead = df_filtered.groupby('owner_name')['Tempo_na_Etapa'].mean()
#     fig_tempo_por_lead = px.bar(x=tempo_por_lead.index, y=tempo_por_lead.values, title="Tempo Médio por Lead por Atendente",
#                                 labels={'x': 'Atendente', 'y': 'Tempo Médio (minutos)'})

#     interacoes_por_lead = df_filtered.groupby('owner_name').size()
#     fig_interacoes_por_lead = px.bar(x=interacoes_por_lead.index, y=interacoes_por_lead.values, title="Interação de Atendentes com os Leads",
#                                      labels={'x': 'Atendente', 'y': 'Número de Leads'})

#     # 9. Contratos Fechados por Atendente
#     contratos_por_atendente = df_filtered[df_filtered['CONTRATO ASSINADO'] == 1].groupby('owner_name').size()
#     fig_contratos_por_atendente = px.bar(x=contratos_por_atendente.index, y=contratos_por_atendente.values, title="Contratos Fechados por Atendente",
#                                          labels={'x': 'Atendente', 'y': 'Número de Contratos Fechados'})

#     # 10. Taxa de conversão por stage_id
#     contratos_stage = df_filtered.groupby('stage_id')['CONTRATO ASSINADO'].sum()
#     leads_stage = df_filtered.groupby('stage_id').size()
#     conversao_stage = (contratos_stage / leads_stage * 100).fillna(0)

#     fig_conversao_stage = px.bar(x=conversao_stage.index, y=conversao_stage.values, title="Taxa de Conversão por Stage",
#                                  labels={'x': 'Stage', 'y': 'Taxa de Conversão (%)'})

#     # Calcular métricas de leads
#     leads_captados_total = len(df_filtered)
#     leads_captados = len(df_filtered_by_problem)
#     proporcao_responderam = (leads_captados / leads_captados_total) * 100 if leads_captados_total > 0 else 0

#     leads_info = [
#         html.H4(f"Leads Captados no Problema Selecionado: {leads_captados}"),
#         html.H4(f"Total de Leads Captados: {leads_captados_total}"),
#         html.H4(f"Proporção de Leads no Problema Selecionado: {proporcao_responderam:.2f}%"),
#     ]

#     return (fig_total_leads, fig_leads_problema, fig_leads_ddd, fig_fluxo_completo, fig_contratos_tempo,
#             fig_tempo_etapa, fig_leads_nao_prosseguiram, fig_motivos_perda_leads,
#             fig_atendimentos_por_dia, fig_tempo_por_lead, fig_interacoes_por_lead,
#             fig_contratos_por_atendente, fig_conversao_stage, leads_info)

# # Callback para o gráfico de tempo na etapa por número de WhatsApp com filtro por problema
# @app.callback(
#     Output('tempo-por-lead-wpp-graph', 'figure'),
#     [Input('problema-dropdown', 'value'),
#      Input('date-picker-range-leads', 'start_date'),
#      Input('date-picker-range-leads', 'end_date')]
# )
# def update_tempo_por_lead_graph(selected_problema, start_date, end_date):
#     # Filtrar dados pela data e pelo problema selecionado
#     df_filtered = df[(df['created_at'] >= pd.to_datetime(start_date)) &
#                      (df['created_at'] <= pd.to_datetime(end_date))]

#     # Filtrar por problema, se um problema foi selecionado
#     if selected_problema:
#         df_filtered = df_filtered[df_filtered['PROBLEMA'] == selected_problema]

#     # Remover valores de tempo na etapa acima de 40 minutos e valores 0
#     df_filtered = df_filtered[(df_filtered['Tempo_na_Etapa'] <= 40) & (df_filtered['Tempo_na_Etapa'] > 0)]

#     # Gráfico de barras para tempo por lead (número de WhatsApp)
#     fig_tempo_por_lead_wpp = px.bar(
#         df_filtered,
#         x='numero_wpp',
#         y='Tempo_na_Etapa',
#         title='Tempo na Etapa por Lead (Filtrado)',
#         labels={'Tempo_na_Etapa': 'Tempo na Etapa (minutos)', 'numero_wpp': 'Número WhatsApp'},
#         hover_data={'Etapa_Final': True}  # Adiciona a etapa final ao hover
#     )

#     return fig_tempo_por_lead_wpp

# if __name__ == '__main__':
#     app.run_server(debug=True)

# Configuração do servidor Flask
server = Flask(__name__)

# Inicializar o app Dash com o servidor Flask, habilitando supressão de exceções de callback
app = dash.Dash(__name__, server=server, external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)

# Utilizando a base de dados df_final_limpo já carregada
df = df_final_limpo

# Aba de Leads
def create_leads_tab():
    return dbc.Col([
        dcc.Tabs([
            dcc.Tab(label='Resumo de Leads', children=[
                dbc.Row([
                    # Adicionando um filtro por tipo de problema
                    dbc.Col([
                        html.P("Selecione o tipo de problema:", className="lead"),
                        dcc.Dropdown(
                            id='problema-dropdown',
                            options=[{'label': problema, 'value': problema} for problema in df['PROBLEMA'].unique()],
                            value=df['PROBLEMA'].unique()[0] if not df.empty else None,  # Valor padrão
                            clearable=False,
                            style={'margin-bottom': '20px'}
                        ),
                        html.P("Selecione o intervalo de datas:", className="lead"),
                        dcc.DatePickerRange(
                            id='date-picker-range-leads',
                            start_date=datetime.now() - timedelta(days=30),
                            end_date=datetime.now(),
                            display_format='DD/MM/YYYY',
                            style={'margin-bottom': '20px'}
                        )
                    ], width=12)
                ]),

                # 1. Total de Leads por Período (primeiro gráfico)
                dbc.Row([
                    dbc.Col(dcc.Graph(id='total-leads-graph'), width=12),
                ]),

                # Informações de leads captados (movidas para abaixo do gráfico)
                dbc.Row([
                    html.Div(id='leads-info', style={'textAlign': 'center', 'marginTop': 20, 'marginBottom': 20}),
                ]),

                # Outros gráficos
                dbc.Row([
                    dbc.Col(dcc.Graph(id='leads-problema-graph'), width=6),  # Gráfico de leads por problema
                    dbc.Col(dcc.Graph(id='leads-ddd-graph'), width=6),  # Gráfico de leads por DDD
                    dbc.Col(dcc.Graph(id='fluxo-completo-graph'), width=6),  # Leads que completaram o fluxo
                    dbc.Col(dcc.Graph(id='contratos-tempo-graph'), width=6),  # Contratos fechados por tempo
                ]),

                # Exibir o gráfico "Tempo na Etapa por Lead (Filtrado)" no final
                dbc.Row([
                    dbc.Col(dcc.Graph(id='tempo-por-lead-wpp-graph'), width=12),  # Gráfico de tempo por lead por número de WhatsApp
                ]),
            ]),

            dcc.Tab(label='Análise Detalhada de Leads', children=[
                dbc.Row([
                    dbc.Col(dcc.Graph(id='tempo-etapa-graph'), width=6),  # Tempo médio por etapa
                    dbc.Col(dcc.Graph(id='leads-nao-prosseguiram-graph'), width=6),  # Leads não prosseguiram
                    dbc.Col(dcc.Graph(id='motivos-perda-leads-graph'), width=6),  # Motivos de perda
                    dbc.Col(dcc.Graph(id='taxa-conversao-por-stage-graph'), width=12)  # Novo gráfico de taxa de conversão por stage_id
                ])
            ])
        ])
    ])

# Aba de Atendentes
def create_atendentes_tab():
    return dbc.Col([
        dcc.Tabs([
            dcc.Tab(label='Atendimentos por Atendente', children=[
                dbc.Row([
                    dbc.Col(dcc.Graph(id='atendimentos-por-dia-graph'), width=6),  # Quantidade de atendimentos por dia
                    dbc.Col(dcc.Graph(id='tempo-por-lead-graph'), width=6),  # Tempo médio gasto por lead
                    dbc.Col(dcc.Graph(id='interacoes-por-lead-graph'), width=6),  # Média de interações por lead
                    dbc.Col(dcc.Graph(id='contratos-por-atendente-graph'), width=6),  # Contratos fechados por atendente
                ])
            ])
        ])
    ])

# Layout do Dashboard
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col([
            html.H2("Dashboard de Dados Solucionaí", className="display-4"),
            html.Hr(),
            dcc.Tabs([
                dcc.Tab(label='Leads', children=[create_leads_tab()]),
                dcc.Tab(label='Atendentes', children=[create_atendentes_tab()])
            ])
        ], width=12),
    ])
], fluid=True)

# Callbacks para atualizar os gráficos dinamicamente
@app.callback(
    [Output('total-leads-graph', 'figure'),
     Output('leads-problema-graph', 'figure'),
     Output('leads-ddd-graph', 'figure'),
     Output('fluxo-completo-graph', 'figure'),
     Output('contratos-tempo-graph', 'figure'),
     Output('tempo-etapa-graph', 'figure'),
     Output('leads-nao-prosseguiram-graph', 'figure'),
     Output('motivos-perda-leads-graph', 'figure'),
     Output('atendimentos-por-dia-graph', 'figure'),
     Output('tempo-por-lead-graph', 'figure'),
     Output('interacoes-por-lead-graph', 'figure'),
     Output('contratos-por-atendente-graph', 'figure'),
     Output('taxa-conversao-por-stage-graph', 'figure'),
     Output('leads-info', 'children')],  # Informações de leads apenas abaixo do primeiro gráfico
    [Input('date-picker-range-leads', 'start_date'),
     Input('date-picker-range-leads', 'end_date'),
     Input('problema-dropdown', 'value')]
)
def update_graphs(start_date, end_date, selected_problema):
    # Filtrar dados pela data
    df_filtered = df[(df['created_at'] >= pd.to_datetime(start_date)) &
                     (df['created_at'] <= pd.to_datetime(end_date))]

    # Filtrar por problema, se um problema foi selecionado
    if selected_problema:
        df_filtered_by_problem = df_filtered[df_filtered['PROBLEMA'] == selected_problema]
    else:
        df_filtered_by_problem = df_filtered

    # 1. Total de Leads Cadastrados na Base por Período de Tempo
    leads_by_date = df_filtered.groupby(df_filtered['created_at'].dt.date).size()
    fig_total_leads = px.line(x=leads_by_date.index, y=leads_by_date.values, title="Total de Leads por Período",
                              labels={'x': 'Data', 'y': 'Número de Leads'})

    # 2. Leads Cadastrados na Base por Tipo de Problema
    leads_by_problem = df_filtered['PROBLEMA'].value_counts()
    fig_leads_problema = px.bar(x=leads_by_problem.index, y=leads_by_problem.values, title="Leads por Tipo de Problema",
                                labels={'x': 'Tipo de Problema', 'y': 'Contagem de Leads'})

    # 3. Leads Cadastrados por Região ou DDD
    leads_by_ddd = df_filtered['Estado'].value_counts()

    # Filtrar para exibir apenas os valores maiores que 1
    leads_by_ddd = leads_by_ddd[leads_by_ddd > 1]

    # Criar o gráfico apenas com os dados filtrados
    fig_leads_ddd = px.bar(x=leads_by_ddd.index, y=leads_by_ddd.values, title="Leads por Região",
                           labels={'x': 'Estado', 'y': 'Contagem de Leads'})

    # 4. Leads que Responderam o Fluxo até o Final
    completed_flow = df_filtered[df_filtered['COMPLETOU_O_FLUXO'] == 1].shape[0]
    fig_fluxo_completo = px.pie(values=[completed_flow, df_filtered.shape[0] - completed_flow],
                                names=['Completaram', 'Não Completaram'],
                                title="Leads que Completaram o Fluxo até o Final")

    # 5. Contratos Fechados por Tempo
    contratos_by_date = df_filtered[df_filtered['CONTRATO ASSINADO'] == 1].groupby(df_filtered['created_at'].dt.date).size()
    fig_contratos_tempo = px.line(x=contratos_by_date.index, y=contratos_by_date.values, title="Contratos Fechados por Período",
                                  labels={'x': 'Data', 'y': 'Número de Contratos Fechados'})

    # 6. Tempo Médio que o Lead Fica em Cada Etapa
    avg_stage_time = df_filtered.groupby('Etapa_Final')['Tempo_na_Etapa'].mean()
    fig_tempo_etapa = px.bar(x=avg_stage_time.index, y=avg_stage_time.values, title="Tempo Médio por Etapa",
                             labels={'x': 'Etapa Final', 'y': 'Tempo Médio (minutos)'})

    # 7. Leads que Não Prosseguiram
    leads_nao_prosseguiram = df_filtered[(df['ClienteDesistiu'] == 1) | (df['SEM RESPOSTA'] == 1)].shape[0]
    fig_leads_nao_prosseguiram = px.pie(values=[leads_nao_prosseguiram, df_filtered.shape[0] - leads_nao_prosseguiram],
                                        names=['Não Prosseguiram', 'Prosseguiram'],
                                        title="Leads que Não Prosseguiram após o Primeiro Contato")

    # 8. Motivo de Perda dos Leads Não Elegíveis
    motivo_perda = df_filtered[df_filtered['NÃO ELEGÍVEL'] == 1]['lost_reason'].value_counts()
    fig_motivos_perda_leads = px.bar(x=motivo_perda.index, y=motivo_perda.values, title="Motivo de Perda dos Leads Não Elegíveis",
                                     labels={'x': 'Motivo', 'y': 'Número de Leads Não Elegíveis'})

    # Gráficos da aba Atendentes (removendo 'Solucionaí' da coluna owner_name)
    df_filtered_atendentes = df_filtered[df_filtered['owner_name'] != 'Solucionaí']

    # 9. Atendimentos por Dia por Atendente
    atendimentos_por_dia = df_filtered_atendentes.groupby([df_filtered_atendentes['created_at'].dt.date, 'owner_name']).size().unstack().fillna(0)
    fig_atendimentos_por_dia = px.line(atendimentos_por_dia, title="Atendimentos por Dia por Atendente",
                                       labels={'x': 'Número de Atendimentos', 'y': 'Dia'})

    # 10. Tempo Médio por Lead por Atendente
    tempo_por_lead = df_filtered_atendentes.groupby('owner_name')['Tempo_na_Etapa'].mean()
    fig_tempo_por_lead = px.bar(x=tempo_por_lead.index, y=tempo_por_lead.values, title="Tempo Médio por Lead por Atendente",
                                labels={'x': 'Atendente', 'y': 'Tempo Médio (minutos)'})

    # 11. Interações por Lead por Atendente
    interacoes_por_lead = df_filtered_atendentes.groupby('owner_name').size()
    fig_interacoes_por_lead = px.bar(x=interacoes_por_lead.index, y=interacoes_por_lead.values, title="Interação de Atendentes com os Leads",
                                     labels={'x': 'Atendente', 'y': 'Número de Leads'})

    # 12. Contratos Fechados por Atendente
    contratos_por_atendente = df_filtered_atendentes[df_filtered_atendentes['CONTRATO ASSINADO'] == 1].groupby('owner_name').size()
    fig_contratos_por_atendente = px.bar(x=contratos_por_atendente.index, y=contratos_por_atendente.values, title="Contratos Fechados por Atendente",
                                         labels={'x': 'Atendente', 'y': 'Número de Contratos Fechados'})

    # 13. Taxa de conversão por stage_id
    contratos_stage = df_filtered.groupby('stage_id')['CONTRATO ASSINADO'].sum()
    leads_stage = df_filtered.groupby('stage_id').size()
    conversao_stage = (contratos_stage / leads_stage * 100).fillna(0)

    fig_conversao_stage = px.bar(x=conversao_stage.index, y=conversao_stage.values, title="Taxa de Conversão por Stage",
                                 labels={'x': 'Stage', 'y': 'Taxa de Conversão (%)'})

    # Calcular métricas de leads
    leads_captados_total = len(df_filtered)
    leads_captados = len(df_filtered_by_problem)
    proporcao_responderam = (leads_captados / leads_captados_total) * 100 if leads_captados_total > 0 else 0

    leads_info = [
        html.H4(f"Leads Captados no Problema Selecionado: {leads_captados}"),
        html.H4(f"Total de Leads Captados: {leads_captados_total}"),
        html.H4(f"Proporção de Leads no Problema Selecionado: {proporcao_responderam:.2f}%"),
    ]

    return (fig_total_leads, fig_leads_problema, fig_leads_ddd, fig_fluxo_completo, fig_contratos_tempo,
            fig_tempo_etapa, fig_leads_nao_prosseguiram, fig_motivos_perda_leads,
            fig_atendimentos_por_dia, fig_tempo_por_lead, fig_interacoes_por_lead,
            fig_contratos_por_atendente, fig_conversao_stage, leads_info)

# Callback para o gráfico de tempo na etapa por número de WhatsApp com filtro por problema
@app.callback(
    Output('tempo-por-lead-wpp-graph', 'figure'),
    [Input('problema-dropdown', 'value'),
     Input('date-picker-range-leads', 'start_date'),
     Input('date-picker-range-leads', 'end_date')]
)
def update_tempo_por_lead_graph(selected_problema, start_date, end_date):
    # Filtrar dados pela data e pelo problema selecionado
    df_filtered = df[(df['created_at'] >= pd.to_datetime(start_date)) &
                     (df['created_at'] <= pd.to_datetime(end_date))]

    # Filtrar por problema, se um problema foi selecionado
    if selected_problema:
        df_filtered = df_filtered[df_filtered['PROBLEMA'] == selected_problema]

    # Remover valores de tempo na etapa acima de 40 minutos e valores 0
    df_filtered = df_filtered[(df_filtered['Tempo_na_Etapa'] <= 40) & (df_filtered['Tempo_na_Etapa'] > 0)]

    # Gráfico de barras para tempo por lead (número de WhatsApp)
    fig_tempo_por_lead_wpp = px.bar(
        df_filtered,
        x='numero_wpp',
        y='Tempo_na_Etapa',
        title='Tempo na Etapa por Lead (Filtrado)',
        labels={'Tempo_na_Etapa': 'Tempo na Etapa (minutos)', 'numero_wpp': 'Número WhatsApp'},
        hover_data={'Etapa_Final': True}  # Adiciona a etapa final ao hover
    )

    return fig_tempo_por_lead_wpp

if __name__ == '__main__':
    app.run_server(debug=True)

# df_final_limpo.to_excel('df_final_limpo.xlsx', index=False)

# from google.colab import files

# # Baixando o arquivo
# files.download('df_final_limpo.xlsx')

